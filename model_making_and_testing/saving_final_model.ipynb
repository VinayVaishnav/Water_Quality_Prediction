{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f587151-64cf-4f7e-b319-0f266b86852a",
   "metadata": {},
   "source": [
    "## Importing the modules & libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5def577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import mode\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d22144",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f422cb5-f3d3-44e8-8ab1-bc53de08ab9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import intel_extension_for_pytorch as ipex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb0082a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db742b59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    '''\n",
    "    Input: (actual labels, predicted labels)\n",
    "    \n",
    "    Displays the confustion matrix heatmap of the input confusion matrix\n",
    "    '''\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    group_names = ['True Negatives','False Postives','False Negatives','True Positives']\n",
    "    group_counts = [f'{value}' for value in conf_mat.flatten()]\n",
    "    group_percentages = [f'{round(value*100, 5)}%' for value in conf_mat.flatten()/np.sum(conf_mat)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(conf_mat, annot=labels, fmt='', cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab1bc4-2359-4abe-a117-85041e0f692e",
   "metadata": {},
   "source": [
    "## Reading the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "322d777f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_water.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d0f949-a13b-4f3c-8b33-5f949c40e816",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pH</th>\n",
       "      <th>Iron</th>\n",
       "      <th>Nitrate</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Lead</th>\n",
       "      <th>Zinc</th>\n",
       "      <th>Color</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Fluoride</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Odor</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Chlorine</th>\n",
       "      <th>Manganese</th>\n",
       "      <th>Total Dissolved Solids</th>\n",
       "      <th>Source</th>\n",
       "      <th>Water Temperature</th>\n",
       "      <th>Air Temperature</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.917863</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>3.734167</td>\n",
       "      <td>227.029851</td>\n",
       "      <td>7.849262e-94</td>\n",
       "      <td>1.245317</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019007</td>\n",
       "      <td>0.622874</td>\n",
       "      <td>0.437835</td>\n",
       "      <td>1.686049</td>\n",
       "      <td>144.010981</td>\n",
       "      <td>432.844908</td>\n",
       "      <td>3.292038</td>\n",
       "      <td>8.024076e-07</td>\n",
       "      <td>284.641984</td>\n",
       "      <td>2</td>\n",
       "      <td>15.348981</td>\n",
       "      <td>71.220586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.443762</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>3.816994</td>\n",
       "      <td>230.995630</td>\n",
       "      <td>5.286616e-76</td>\n",
       "      <td>0.528280</td>\n",
       "      <td>3</td>\n",
       "      <td>0.319956</td>\n",
       "      <td>0.423423</td>\n",
       "      <td>0.431588</td>\n",
       "      <td>3.414619</td>\n",
       "      <td>275.702107</td>\n",
       "      <td>990.201209</td>\n",
       "      <td>3.560224</td>\n",
       "      <td>7.007989e-02</td>\n",
       "      <td>570.054094</td>\n",
       "      <td>4</td>\n",
       "      <td>11.643467</td>\n",
       "      <td>44.891330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.091909</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>9.925788</td>\n",
       "      <td>186.540872</td>\n",
       "      <td>4.171069e-132</td>\n",
       "      <td>3.807511</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>0.222912</td>\n",
       "      <td>0.616574</td>\n",
       "      <td>0.795310</td>\n",
       "      <td>175.275175</td>\n",
       "      <td>385.025855</td>\n",
       "      <td>3.177849</td>\n",
       "      <td>3.296139e-03</td>\n",
       "      <td>168.075545</td>\n",
       "      <td>5</td>\n",
       "      <td>15.249416</td>\n",
       "      <td>69.336671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.445251</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.702584</td>\n",
       "      <td>162.828458</td>\n",
       "      <td>6.102202e-23</td>\n",
       "      <td>3.742464</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504791</td>\n",
       "      <td>0.054562</td>\n",
       "      <td>0.851326</td>\n",
       "      <td>1.270483</td>\n",
       "      <td>40.853403</td>\n",
       "      <td>273.359662</td>\n",
       "      <td>3.957842</td>\n",
       "      <td>2.863952e-04</td>\n",
       "      <td>365.639045</td>\n",
       "      <td>6</td>\n",
       "      <td>13.966842</td>\n",
       "      <td>45.444798</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.132455</td>\n",
       "      <td>0.055262</td>\n",
       "      <td>4.288010</td>\n",
       "      <td>94.993978</td>\n",
       "      <td>2.919909e-52</td>\n",
       "      <td>1.770221</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021703</td>\n",
       "      <td>1.111893</td>\n",
       "      <td>0.247116</td>\n",
       "      <td>0.426404</td>\n",
       "      <td>146.073521</td>\n",
       "      <td>265.530096</td>\n",
       "      <td>1.706755</td>\n",
       "      <td>3.083768e-02</td>\n",
       "      <td>266.079565</td>\n",
       "      <td>0</td>\n",
       "      <td>27.920380</td>\n",
       "      <td>68.104498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120105</th>\n",
       "      <td>7.336513</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>3.807672</td>\n",
       "      <td>89.956213</td>\n",
       "      <td>4.258296e-34</td>\n",
       "      <td>3.027267</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>0.745372</td>\n",
       "      <td>0.186357</td>\n",
       "      <td>2.585437</td>\n",
       "      <td>145.362834</td>\n",
       "      <td>533.374053</td>\n",
       "      <td>2.553024</td>\n",
       "      <td>1.428103e-02</td>\n",
       "      <td>1.634232</td>\n",
       "      <td>2</td>\n",
       "      <td>18.610969</td>\n",
       "      <td>82.445237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120106</th>\n",
       "      <td>8.161283</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>6.552120</td>\n",
       "      <td>309.134213</td>\n",
       "      <td>3.368973e-44</td>\n",
       "      <td>2.127818</td>\n",
       "      <td>3</td>\n",
       "      <td>0.201469</td>\n",
       "      <td>3.419696</td>\n",
       "      <td>3.170538</td>\n",
       "      <td>1.931928</td>\n",
       "      <td>43.043399</td>\n",
       "      <td>366.349236</td>\n",
       "      <td>3.180415</td>\n",
       "      <td>7.086033e-04</td>\n",
       "      <td>19.767936</td>\n",
       "      <td>6</td>\n",
       "      <td>26.160882</td>\n",
       "      <td>45.900772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120107</th>\n",
       "      <td>8.418457</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>8.427576</td>\n",
       "      <td>256.570863</td>\n",
       "      <td>4.751543e-26</td>\n",
       "      <td>4.967504</td>\n",
       "      <td>2</td>\n",
       "      <td>3.824532</td>\n",
       "      <td>0.541850</td>\n",
       "      <td>0.284838</td>\n",
       "      <td>0.299860</td>\n",
       "      <td>371.261098</td>\n",
       "      <td>339.150786</td>\n",
       "      <td>2.630130</td>\n",
       "      <td>9.608234e-03</td>\n",
       "      <td>545.990529</td>\n",
       "      <td>7</td>\n",
       "      <td>21.436974</td>\n",
       "      <td>70.493951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120108</th>\n",
       "      <td>7.950573</td>\n",
       "      <td>0.215729</td>\n",
       "      <td>4.677850</td>\n",
       "      <td>292.727780</td>\n",
       "      <td>4.679421e-12</td>\n",
       "      <td>1.842063</td>\n",
       "      <td>1</td>\n",
       "      <td>1.181166</td>\n",
       "      <td>2.747241</td>\n",
       "      <td>1.367155</td>\n",
       "      <td>3.749374</td>\n",
       "      <td>198.070171</td>\n",
       "      <td>521.505506</td>\n",
       "      <td>3.555576</td>\n",
       "      <td>1.875424e-11</td>\n",
       "      <td>514.136530</td>\n",
       "      <td>1</td>\n",
       "      <td>19.064632</td>\n",
       "      <td>67.052475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120109</th>\n",
       "      <td>7.539523</td>\n",
       "      <td>0.022760</td>\n",
       "      <td>4.902591</td>\n",
       "      <td>106.256430</td>\n",
       "      <td>1.399449e-10</td>\n",
       "      <td>1.069694</td>\n",
       "      <td>3</td>\n",
       "      <td>0.371766</td>\n",
       "      <td>0.995846</td>\n",
       "      <td>1.665171</td>\n",
       "      <td>2.530943</td>\n",
       "      <td>79.593261</td>\n",
       "      <td>282.713146</td>\n",
       "      <td>6.033203</td>\n",
       "      <td>2.838596e-01</td>\n",
       "      <td>118.556879</td>\n",
       "      <td>0</td>\n",
       "      <td>6.594036</td>\n",
       "      <td>51.751181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120110 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pH      Iron   Nitrate    Chloride           Lead      Zinc   \n",
       "0        6.917863  0.000081  3.734167  227.029851   7.849262e-94  1.245317  \\\n",
       "1        5.443762  0.020106  3.816994  230.995630   5.286616e-76  0.528280   \n",
       "2        8.091909  0.002167  9.925788  186.540872  4.171069e-132  3.807511   \n",
       "3        7.445251  0.000006  1.702584  162.828458   6.102202e-23  3.742464   \n",
       "4        8.132455  0.055262  4.288010   94.993978   2.919909e-52  1.770221   \n",
       "...           ...       ...       ...         ...            ...       ...   \n",
       "5120105  7.336513  0.000799  3.807672   89.956213   4.258296e-34  3.027267   \n",
       "5120106  8.161283  0.000015  6.552120  309.134213   3.368973e-44  2.127818   \n",
       "5120107  8.418457  0.000095  8.427576  256.570863   4.751543e-26  4.967504   \n",
       "5120108  7.950573  0.215729  4.677850  292.727780   4.679421e-12  1.842063   \n",
       "5120109  7.539523  0.022760  4.902591  106.256430   1.399449e-10  1.069694   \n",
       "\n",
       "         Color  Turbidity  Fluoride    Copper      Odor     Sulfate   \n",
       "0            2   0.019007  0.622874  0.437835  1.686049  144.010981  \\\n",
       "1            3   0.319956  0.423423  0.431588  3.414619  275.702107   \n",
       "2            3   0.004867  0.222912  0.616574  0.795310  175.275175   \n",
       "3            1   0.504791  0.054562  0.851326  1.270483   40.853403   \n",
       "4            3   0.021703  1.111893  0.247116  0.426404  146.073521   \n",
       "...        ...        ...       ...       ...       ...         ...   \n",
       "5120105      2   0.010288  0.745372  0.186357  2.585437  145.362834   \n",
       "5120106      3   0.201469  3.419696  3.170538  1.931928   43.043399   \n",
       "5120107      2   3.824532  0.541850  0.284838  0.299860  371.261098   \n",
       "5120108      1   1.181166  2.747241  1.367155  3.749374  198.070171   \n",
       "5120109      3   0.371766  0.995846  1.665171  2.530943   79.593261   \n",
       "\n",
       "         Conductivity  Chlorine     Manganese  Total Dissolved Solids  Source   \n",
       "0          432.844908  3.292038  8.024076e-07              284.641984       2  \\\n",
       "1          990.201209  3.560224  7.007989e-02              570.054094       4   \n",
       "2          385.025855  3.177849  3.296139e-03              168.075545       5   \n",
       "3          273.359662  3.957842  2.863952e-04              365.639045       6   \n",
       "4          265.530096  1.706755  3.083768e-02              266.079565       0   \n",
       "...               ...       ...           ...                     ...     ...   \n",
       "5120105    533.374053  2.553024  1.428103e-02                1.634232       2   \n",
       "5120106    366.349236  3.180415  7.086033e-04               19.767936       6   \n",
       "5120107    339.150786  2.630130  9.608234e-03              545.990529       7   \n",
       "5120108    521.505506  3.555576  1.875424e-11              514.136530       1   \n",
       "5120109    282.713146  6.033203  2.838596e-01              118.556879       0   \n",
       "\n",
       "         Water Temperature  Air Temperature  Target  \n",
       "0                15.348981        71.220586       0  \n",
       "1                11.643467        44.891330       0  \n",
       "2                15.249416        69.336671       0  \n",
       "3                13.966842        45.444798       0  \n",
       "4                27.920380        68.104498       0  \n",
       "...                    ...              ...     ...  \n",
       "5120105          18.610969        82.445237       1  \n",
       "5120106          26.160882        45.900772       1  \n",
       "5120107          21.436974        70.493951       1  \n",
       "5120108          19.064632        67.052475       1  \n",
       "5120109           6.594036        51.751181       1  \n",
       "\n",
       "[5120110 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cf578-3eb6-4428-93af-a3ccb523f88e",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training, validation and test sets (70:10:20 ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8005d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"Target\", axis=1)\n",
    "y = df[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48e973df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5120110 entries, 0 to 5120109\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   pH                      float64\n",
      " 1   Iron                    float64\n",
      " 2   Nitrate                 float64\n",
      " 3   Chloride                float64\n",
      " 4   Lead                    float64\n",
      " 5   Zinc                    float64\n",
      " 6   Color                   int64  \n",
      " 7   Turbidity               float64\n",
      " 8   Fluoride                float64\n",
      " 9   Copper                  float64\n",
      " 10  Odor                    float64\n",
      " 11  Sulfate                 float64\n",
      " 12  Conductivity            float64\n",
      " 13  Chlorine                float64\n",
      " 14  Manganese               float64\n",
      " 15  Total Dissolved Solids  float64\n",
      " 16  Source                  int64  \n",
      " 17  Water Temperature       float64\n",
      " 18  Air Temperature         float64\n",
      "dtypes: float64(17), int64(2)\n",
      "memory usage: 742.2 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfae9788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 5120110 entries, 0 to 5120109\n",
      "Series name: Target\n",
      "Non-Null Count    Dtype\n",
      "--------------    -----\n",
      "5120110 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 39.1 MB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34a113db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "874ffea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tabnet(X_train_, y_train_):\n",
    "    clf = TabNetClassifier()\n",
    "    clf.fit(\n",
    "        X_train_, y_train_,\n",
    "        max_epochs=5,\n",
    "    )\n",
    "    return clf\n",
    "\n",
    "def ensemble(Xs, ys):\n",
    "    clfs = [train_tabnet(Xs[i], ys[i]) for i in range(len(Xs))]\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34fc4c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\n",
      "2023-09-23 18:37:05,276 - sklearnex - INFO - sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\n",
      "INFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\n",
      "2023-09-23 18:37:05,279 - sklearnex - INFO - sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\n",
      "INFO:sklearnex: sklearn.model_selection.train_test_split: running accelerated version on CPU\n",
      "2023-09-23 18:37:06,422 - sklearnex - INFO - sklearn.model_selection.train_test_split: running accelerated version on CPU\n",
      "INFO:sklearnex: sklearn.model_selection.train_test_split: running accelerated version on CPU\n",
      "2023-09-23 18:37:07,183 - sklearnex - INFO - sklearn.model_selection.train_test_split: running accelerated version on CPU\n",
      "INFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\n",
      "2023-09-23 18:37:07,459 - sklearnex - INFO - sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\n",
      "INFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\n",
      "2023-09-23 18:37:07,460 - sklearnex - INFO - sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\n",
      "INFO:sklearnex: sklearn.model_selection.train_test_split: running accelerated version on CPU\n",
      "2023-09-23 18:37:08,231 - sklearnex - INFO - sklearn.model_selection.train_test_split: running accelerated version on CPU\n",
      "INFO:sklearnex: sklearn.model_selection.train_test_split: running accelerated version on CPU\n",
      "2023-09-23 18:37:08,562 - sklearnex - INFO - sklearn.model_selection.train_test_split: running accelerated version on CPU\n"
     ]
    }
   ],
   "source": [
    "X_train_1, X_temp, y_train_1, y_temp = tts(X, y, test_size=.66, stratify=y, random_state=42)\n",
    "X_train_2, X_train_3, y_train_2, y_train_3 = tts(X_temp, y_temp, test_size=.5, stratify=y_temp, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "288a98d6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\n",
      "2023-09-23 18:37:20,982 - sklearnex - INFO - sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.34136 |  0:00:51s\n",
      "epoch 1  | loss: 0.30737 |  0:01:42s\n",
      "epoch 2  | loss: 0.30307 |  0:02:33s\n",
      "epoch 3  | loss: 0.30207 |  0:03:24s\n",
      "epoch 4  | loss: 0.29787 |  0:04:15s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m clf1 \u001b[38;5;241m=\u001b[39m TabNetClassifier()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:278\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_importance:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# compute feature importance once the best model is defined\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_importances_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_feature_importances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:759\u001b[0m, in \u001b[0;36mTabModel._compute_feature_importances\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_feature_importances\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    751\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute global feature importance.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \n\u001b[1;32m    753\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 759\u001b[0m     M_explain, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     sum_explain \u001b[38;5;241m=\u001b[39m M_explain\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    761\u001b[0m     feature_importances_ \u001b[38;5;241m=\u001b[39m sum_explain \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(sum_explain)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:358\u001b[0m, in \u001b[0;36mTabModel.explain\u001b[0;34m(self, X, normalize)\u001b[0m\n\u001b[1;32m    356\u001b[0m M_explain, masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mforward_masks(data)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m masks\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 358\u001b[0m     masks[key] \u001b[38;5;241m=\u001b[39m \u001b[43mcsc_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreducing_matrix\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m original_feat_explain \u001b[38;5;241m=\u001b[39m csc_matrix\u001b[38;5;241m.\u001b[39mdot(M_explain\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    362\u001b[0m                                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreducing_matrix)\n\u001b[1;32m    363\u001b[0m res_explain\u001b[38;5;241m.\u001b[39mappend(original_feat_explain)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_base.py:416\u001b[0m, in \u001b[0;36mspmatrix.dot\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m*\u001b[39m other\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_base.py:636\u001b[0m, in \u001b[0;36mspmatrix.__rmatmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    635\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_base.py:614\u001b[0m, in \u001b[0;36mspmatrix._rmul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    613\u001b[0m     tr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(other)\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[0;32m--> 614\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_mul_dispatch(tr)\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_csc.py:116\u001b[0m, in \u001b[0;36mcsc_matrix.transpose\u001b[0;34m(self, axes, copy)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparse matrices do not support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter because swapping \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimensions is the only logical permutation.\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    114\u001b[0m M, N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_csr_container\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_compressed.py:106\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_compressed.py:181\u001b[0m, in \u001b[0;36m_cs_matrix.check_format\u001b[0;34m(self, full_check)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices)):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLast value of index pointer should be less than \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe size of index and data arrays\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprune\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_check:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# check format validity (more expensive)\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_compressed.py:1180\u001b[0m, in \u001b[0;36m_cs_matrix.prune\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz:\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata array has fewer than nnz elements\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1180\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m \u001b[38;5;241m=\u001b[39m _prune_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz])\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m _prune_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf1 = TabNetClassifier()\n",
    "clf1.fit(X_train_1, y_train_1, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a601bb18",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\n",
      "2023-09-23 18:42:13,842 - sklearnex - INFO - sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.33786 |  0:00:51s\n",
      "epoch 1  | loss: 0.3026  |  0:01:43s\n",
      "epoch 2  | loss: 0.29675 |  0:02:35s\n",
      "epoch 3  | loss: 0.29378 |  0:03:26s\n",
      "epoch 4  | loss: 0.2944  |  0:04:18s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m clf2 \u001b[38;5;241m=\u001b[39m TabNetClassifier()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:278\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_importance:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# compute feature importance once the best model is defined\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_importances_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_feature_importances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:759\u001b[0m, in \u001b[0;36mTabModel._compute_feature_importances\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_feature_importances\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    751\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute global feature importance.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \n\u001b[1;32m    753\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 759\u001b[0m     M_explain, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     sum_explain \u001b[38;5;241m=\u001b[39m M_explain\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    761\u001b[0m     feature_importances_ \u001b[38;5;241m=\u001b[39m sum_explain \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(sum_explain)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:369\u001b[0m, in \u001b[0;36mTabModel.explain\u001b[0;34m(self, X, normalize)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m masks\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 369\u001b[0m             res_masks[key] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mres_masks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m res_explain \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(res_explain)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    281\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf2 = TabNetClassifier()\n",
    "clf2.fit(X_train_2, y_train_2, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e21fbf65",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\n",
      "2023-09-23 18:46:57,991 - sklearnex - INFO - sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.33905 |  0:00:52s\n",
      "epoch 1  | loss: 0.30938 |  0:01:44s\n",
      "epoch 2  | loss: 0.30805 |  0:02:35s\n",
      "epoch 3  | loss: 0.30495 |  0:03:27s\n",
      "epoch 4  | loss: 0.3027  |  0:04:19s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m clf3 \u001b[38;5;241m=\u001b[39m TabNetClassifier()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclf3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:278\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_importance:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# compute feature importance once the best model is defined\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_importances_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_feature_importances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:759\u001b[0m, in \u001b[0;36mTabModel._compute_feature_importances\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_feature_importances\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    751\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute global feature importance.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \n\u001b[1;32m    753\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 759\u001b[0m     M_explain, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     sum_explain \u001b[38;5;241m=\u001b[39m M_explain\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    761\u001b[0m     feature_importances_ \u001b[38;5;241m=\u001b[39m sum_explain \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(sum_explain)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:369\u001b[0m, in \u001b[0;36mTabModel.explain\u001b[0;34m(self, X, normalize)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m masks\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 369\u001b[0m             res_masks[key] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mres_masks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m res_explain \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(res_explain)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    281\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf3 = TabNetClassifier()\n",
    "clf3.fit(X_train_3, y_train_3, max_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701203e1",
   "metadata": {},
   "source": [
    "### The above cells had to be stopped manually after the completion of all the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e3205a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'models'\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e11a8847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at ./models/model_1.zip\n"
     ]
    }
   ],
   "source": [
    "clf1_path = \"./models/model_1\"\n",
    "clf1_saved_path = clf1.save_model(clf1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b31d0381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at ./models/model_2.zip\n"
     ]
    }
   ],
   "source": [
    "clf2_path = \"./models/model_2\"\n",
    "clf2_saved_path = clf2.save_model(clf2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8f55f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at ./models/model_3.zip\n"
     ]
    }
   ],
   "source": [
    "clf3_path = \"./models/model_3\"\n",
    "clf3_saved_path = clf3.save_model(clf3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da725c-56c0-4fec-87c2-c95990552d3f",
   "metadata": {},
   "source": [
    "## Data required for making the final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd0334d-723e-49bf-9daf-8d57747d8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_column_rows = ['Iron', 'Nitrate', 'Lead', 'Color', 'Turbidity', 'Odor', 'Chlorine', 'Total Dissolved Solids', \n",
    "                    'Source', 'Air Temperature', 'Month', 'Day', 'Time of Day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b9ca5d1-eb02-46fc-af16-9954e9d09233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.445251285427391, 184.3043772737876, 1.5504042963151854, 0.9647085346855051, 0.5162646133771908, 146.07352061294569, 425.01489236635155, 0.10923347178334412, 19.128374309638666]\n"
     ]
    }
   ],
   "source": [
    "fillna_cols = ['pH', 'Chloride', 'Zinc', 'Fluoride', 'Copper', 'Sulfate', 'Conductivity', 'Manganese', 'Water Temperature']\n",
    "fillna_cols_means = [np.mean(df[each]) for each in fillna_cols]\n",
    "print(fillna_cols_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f631727-8545-44d1-ac7b-3ccadf3937da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sourceslist = ['Aquifer', 'Ground', 'Lake', 'Reservoir', 'River', 'Spring', 'Stream', 'Well']\n",
    "replacesourceslist = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "colorslist = ['Colorless', 'Near Colorless', 'Faint Yellow', 'Light Yellow', 'Yellow']\n",
    "replacecolorslist = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b575db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
